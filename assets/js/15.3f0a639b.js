(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{487:function(t,s,a){t.exports=a.p+"assets/img/0106_001.215e3fed.png"},488:function(t,s,a){t.exports=a.p+"assets/img/0106_002.8cb5fe29.png"},489:function(t,s,a){t.exports=a.p+"assets/img/0106_003.45563aee.png"},490:function(t,s,a){t.exports=a.p+"assets/img/0106_004.32de4579.png"},491:function(t,s,a){t.exports=a.p+"assets/img/0106_005.19f4970e.png"},911:function(t,s,a){"use strict";a.r(s);var n=a(25),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"_106-从中序与后序遍历序列构造二叉树"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_106-从中序与后序遍历序列构造二叉树"}},[t._v("#")]),t._v(" 106. 从中序与后序遍历序列构造二叉树")]),t._v(" "),n("Valine"),t._v(" "),n("h2",{attrs:{id:"题目描述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#题目描述"}},[t._v("#")]),t._v(" 题目描述")]),t._v(" "),n("p",[t._v("题目传送门："),n("a",{attrs:{href:"https://leetcode-cn.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/",target:"_blank",rel:"noopener noreferrer"}},[t._v("106. 从中序与后序遍历序列构造二叉树"),n("OutboundLink")],1)]),t._v(" "),n("p",[t._v("根据一棵树的中序遍历与后序遍历构造二叉树。")]),t._v(" "),n("p",[n("strong",[t._v("注意:")])]),t._v(" "),n("p",[t._v("你可以假设树中没有重复的元素。")]),t._v(" "),n("p",[t._v("例如，给出")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("中序遍历 inorder = [9,3,15,20,7]\n后序遍历 postorder = [9,15,7,20,3]\n")])])]),n("p",[t._v("返回如下的二叉树：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("    3\n   / \\\n  9  20\n    /  \\\n   15   7\n")])])]),n("h2",{attrs:{id:"题解"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#题解"}},[t._v("#")]),t._v(" 题解")]),t._v(" "),n("p",[t._v("搬运自： "),n("a",{attrs:{href:"https://leetcode-cn.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/solution/tu-jie-gou-zao-er-cha-shu-wei-wan-dai-xu-by-user72/",target:"_blank",rel:"noopener noreferrer"}},[t._v("图解构造二叉树之中序+后序"),n("OutboundLink")],1),t._v("  感谢大佬，一看就懂！")]),t._v(" "),n("p",[t._v("解决此问题的关键在于要很熟悉树的各种遍历次序代表的什么，最好能够将图画出来。本题解带你先进行中序遍历和后续遍历二叉树，然后再根据遍历结果将二叉树进行还原。")]),t._v(" "),n("p",[t._v("下面是一棵树：")]),t._v(" "),n("div",{attrs:{align:"center"}},[n("img",{staticClass:"zoom-custom-imgs",attrs:{src:a(487),width:"300px"}})]),t._v(" "),n("p",[t._v("其中序遍历和后序遍历的结果如下：")]),t._v(" "),n("div",{attrs:{align:"center"}},[n("img",{staticClass:"zoom-custom-imgs",attrs:{src:a(488),width:"600px"}})]),t._v(" "),n("p",[n("strong",[t._v("根据中序和后序遍历结果还原二叉树")])]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("中序遍历和后续遍历的特性")])])]),t._v(" "),n("p",[t._v("首先来看题目给出的两个已知条件 "),n("strong",[t._v("中序遍历序列")]),t._v(" 和 "),n("strong",[t._v("后序遍历序列")]),t._v(" 根据这两种遍历的特性我们可以得出两个结论")]),t._v(" "),n("ol",[n("li",[t._v("在后序遍历序列中,最后一个元素为树的根节点")]),t._v(" "),n("li",[t._v("在中序遍历序列中,根节点的左边为左子树，根节点的右边为右子树")])]),t._v(" "),n("div",{attrs:{align:"center"}},[n("img",{staticClass:"zoom-custom-imgs",attrs:{src:a(489),width:"500px"}})]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("树的还原过程描述")])])]),t._v(" "),n("p",[t._v("根据中序遍历和后续遍历的特性我们进行树的还原过程分析")]),t._v(" "),n("ol",[n("li",[t._v("首先在后序遍历序列中找到根节点(最后一个元素)")]),t._v(" "),n("li",[t._v("根据根节点在中序遍历序列中找到根节点的位置")]),t._v(" "),n("li",[t._v("根据根节点的位置将中序遍历序列分为左子树和右子树")]),t._v(" "),n("li",[t._v("根据根节点的位置确定左子树和右子树在中序数组和后续数组中的左右边界位置")]),t._v(" "),n("li",[t._v("递归构造左子树和右子树")]),t._v(" "),n("li",[t._v("返回根节点结束")])]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("树的还原过程变量定义")])])]),t._v(" "),n("p",[t._v("需要定义几个变量帮助我们进行树的还原")]),t._v(" "),n("blockquote",[n("p",[t._v("变量说明：")]),t._v(" "),n("blockquote",[n("p",[t._v("is: inorderStart")]),t._v(" "),n("p",[t._v("ie: inorderEnd")]),t._v(" "),n("p",[t._v("ps: postorderStart")]),t._v(" "),n("p",[t._v("pe: postorderEnd")]),t._v(" "),n("p",[t._v("ri: rootIndex")])])]),t._v(" "),n("ol",[n("li",[n("code",[t._v("HashMap memo")]),t._v(" 需要一个哈希表来保存中序遍历序列中，元素和索引的位置关系。因为从后序序列中拿到根节点后，要在中序序列中查找对应的位置，从而将数组分为左子树和右子树")]),t._v(" "),n("li",[n("code",[t._v("int ri")]),t._v("根节点在中序遍历数组中的索引位置")]),t._v(" "),n("li",[t._v("中序遍历数组的两个位置标记 "),n("code",[t._v("[is, ie]")]),t._v("，is 是起始位置，ie 是结束位置")]),t._v(" "),n("li",[t._v("后序遍历数组的两个位置标记 "),n("code",[t._v("[ps, pe]")]),t._v(" ps 是起始位置，pe 是结束位置")])]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("位置关系的计算")])])]),t._v(" "),n("p",[t._v("在找到根节点位置以后，我们要确定下一轮中，左子树和右子树在中序数组和后续数组中的左右边界的位置。")]),t._v(" "),n("ol",[n("li",[t._v("左子树-中序数组 "),n("code",[t._v("is = is")]),t._v(", "),n("code",[t._v("ie = ri - 1")])]),t._v(" "),n("li",[t._v("左子树-后序数组 "),n("code",[t._v("ps = ps")]),t._v(", "),n("code",[t._v("pe = ps + ri - is - 1")]),t._v(" (pe计算过程解释，后续数组的起始位置加上左子树长度-1 就是后后序数组结束位置了，左子树的长度 = 根节点索引-左子树)")]),t._v(" "),n("li",[t._v("右子树-中序数组 "),n("code",[t._v("is = ri + 1, ie = ie")])]),t._v(" "),n("li",[t._v("右子树-后序数组"),n("code",[t._v("ps = ps + ri - is, pe - 1")])])]),t._v(" "),n("p",[t._v("听不明白没关系，看图就对了，计算图示如下")]),t._v(" "),n("div",{attrs:{align:"center"}},[n("img",{staticClass:"zoom-custom-imgs",attrs:{src:a(490),width:"600px"}})]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("树的还原过程")])])]),t._v(" "),n("div",{attrs:{align:"center"}},[n("img",{staticClass:"zoom-custom-imgs",attrs:{src:a(491),width:"500px"}})]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("代码")])])]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Solution")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" memo "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" post"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TreeNode")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("buildTree")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" inorder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" postorder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将中序遍历的节点值和索引记录在哈希表中")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" inorder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" memo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inorder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        post "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" postorder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("buildTree")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inorder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" postorder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * 根据边界构建树\n     * @param is inorderStart\n     * @param ie inorderEnd\n     * @param ps postorderStart\n     * @param pe postorderEnd\n     * @return\n     */")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TreeNode")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("buildTree")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" is"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" ie"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" pe"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("is "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ie "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" ps "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" pe"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 根据后序遍历的结果取得根节点")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" rootValue "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" post"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("pe"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 得到 根节点 在中序遍历数组中的下标。 ri 即 rootIndex.")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" ri "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" memo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rootValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TreeNode")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TreeNode")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rootValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("buildTree")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("is"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ri "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ps "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" ri "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" is "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("buildTree")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ri "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ie"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ps "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" ri "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" is"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pe "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注意、返回的是新建立的node")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])],1)}),[],!1,null,null,null);s.default=e.exports}}]);